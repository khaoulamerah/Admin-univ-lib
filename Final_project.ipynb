{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaoulamerah/Admin-univ-lib/blob/main/Final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ppM7lVyUtlf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "itUzRVwhU2II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "sZraum55VHo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(\"/content/drive/MyDrive/Faces/train/\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ke_dctxhVK1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "7lIUud9hVN-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "happy = list(data_dir.glob('happy/*'))\n",
        "PIL.Image.open(str(happy[0]))"
      ],
      "metadata": {
        "id": "PHgQtcboVQ1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(happy[1]))"
      ],
      "metadata": {
        "id": "frFozlyMVTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sad = list(data_dir.glob('sad/*'))\n",
        "PIL.Image.open(str(sad[0]))"
      ],
      "metadata": {
        "id": "spAQkGDvVdoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(sad[1]))"
      ],
      "metadata": {
        "id": "XPXvr8bRVhmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "bqhnbKuGViaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "u07HfYEXVidl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "sbRb3nFpVij9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "2hbenErbVpEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(4):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "6OJ5Rgs1Vs64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "12pKe34rVvq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "GIOSvowVVyf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "t9D8kaqdV09S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "udwZYzazV3W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "D4U6uAWhV5cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GFHKdXCnV8Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YZf7miANWGvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "iILH6Bj1WIEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mr8uA9yVWKEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/emotion_recognition_model.h5')\n",
        "print(\"Model saved successfully as '/content/drive/MyDrive/emotion_recognition_model.h5'\")"
      ],
      "metadata": {
        "id": "rktgFnjiWKII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 2: Import required libraries for classification\n",
        "# Add this cell for the classification functionality\n",
        "\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the emotion classes (matching your project structure)\n",
        "EMOTION_CLASSES = ['angry', 'fear', 'happy', 'sad']\n",
        "\n",
        "# Cell 3: Function to take photo and classify emotion\n",
        "# Add this cell for the webcam classification function\n",
        "\n",
        "def take_photo_and_classify_emotion(model, filename='photo.jpg', quality=0.8):\n",
        "    \"\"\"\n",
        "    Take a photo using webcam and classify the emotion\n",
        "\n",
        "    Args:\n",
        "        model: Trained emotion recognition model\n",
        "        filename: Name to save the captured photo\n",
        "        quality: JPEG quality (0-1)\n",
        "    \"\"\"\n",
        "    # Define JavaScript to open camera and take photo\n",
        "    js = f'''\n",
        "        async function takePhoto(quality) {{\n",
        "          const div = document.createElement('div');\n",
        "          const capture = document.createElement('button');\n",
        "          capture.textContent = 'Take Photo for Emotion Recognition';\n",
        "          capture.style.padding = '10px 20px';\n",
        "          capture.style.fontSize = '16px';\n",
        "          capture.style.backgroundColor = '#4CAF50';\n",
        "          capture.style.color = 'white';\n",
        "          capture.style.border = 'none';\n",
        "          capture.style.borderRadius = '5px';\n",
        "          capture.style.cursor = 'pointer';\n",
        "          div.appendChild(capture);\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          video.style.width = '400px';\n",
        "          video.style.height = '300px';\n",
        "          video.style.border = '2px solid #333';\n",
        "          video.style.borderRadius = '10px';\n",
        "\n",
        "          const stream = await navigator.mediaDevices.getUserMedia({{video: true}});\n",
        "\n",
        "          document.body.appendChild(div);\n",
        "          div.appendChild(video);\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          // Resize the output to fit the video element.\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          // Wait for Capture to be clicked.\n",
        "          await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          return canvas.toDataURL('image/jpeg', quality);\n",
        "        }}\n",
        "        '''\n",
        "\n",
        "    # Display JavaScript to take photo and capture it\n",
        "    output.eval_js(js)\n",
        "\n",
        "    # Retrieve and decode the photo\n",
        "    data = output.eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    # Load the image and preprocess it for classification\n",
        "    image = Image.open(filename)\n",
        "    image = image.resize((180, 180))  # Match your model's input size\n",
        "    image = np.array(image)\n",
        "    image = image.astype('float32') / 255.0  # Normalize to [0,1]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Use the model to classify the image\n",
        "    predictions = model.predict(image)[0]\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    predicted_emotion = EMOTION_CLASSES[predicted_class_index]\n",
        "    confidence = predictions[predicted_class_index]\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EMOTION RECOGNITION RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Predicted Emotion: {predicted_emotion.upper()}\")\n",
        "    print(f\"Confidence: {confidence:.2%}\")\n",
        "    print(\"\\nAll Emotion Probabilities:\")\n",
        "\n",
        "    # Sort emotions by probability (highest first)\n",
        "    emotion_probs = list(zip(EMOTION_CLASSES, predictions))\n",
        "    emotion_probs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    for emotion, prob in emotion_probs:\n",
        "        print(f\"  {emotion.capitalize()}: {prob:.2%}\")\n",
        "\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return predicted_emotion, confidence, predictions\n",
        "\n",
        "# Cell 4: Function to classify existing image files\n",
        "# Add this cell for classifying existing images\n",
        "\n",
        "def classify_image_file(model, image_path, target_size=(180, 180)):\n",
        "    \"\"\"\n",
        "    Classify emotion from an existing image file\n",
        "\n",
        "    Args:\n",
        "        model: Trained emotion recognition model\n",
        "        image_path: Path to the image file\n",
        "        target_size: Size to resize the image (width, height)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        image = Image.open(image_path)\n",
        "        image = image.resize(target_size)\n",
        "        image = np.array(image)\n",
        "        image = image.astype('float32') / 255.0\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = model.predict(image)[0]\n",
        "        predicted_class_index = np.argmax(predictions)\n",
        "        predicted_emotion = EMOTION_CLASSES[predicted_class_index]\n",
        "        confidence = predictions[predicted_class_index]\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\nImage: {image_path}\")\n",
        "        print(f\"Predicted Emotion: {predicted_emotion.upper()}\")\n",
        "        print(f\"Confidence: {confidence:.2%}\")\n",
        "\n",
        "        return predicted_emotion, confidence, predictions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Cell 5: Test the classification with webcam\n",
        "# Add this cell to test the webcam functionality\n",
        "\n",
        "# Take a photo and classify emotion\n",
        "print(\"Taking photo for emotion recognition...\")\n",
        "emotion, confidence, all_predictions = take_photo_and_classify_emotion(model)\n",
        "\n",
        "# Cell 6: Test with existing images from your dataset\n",
        "# Add this cell to test with your training images\n",
        "\n",
        "# Example: Test with a happy image from your dataset\n",
        "happy_images = list(data_dir.glob('happy/*.jpg'))\n",
        "if happy_images:\n",
        "    test_image_path = str(happy_images[0])\n",
        "    print(f\"Testing with image: {test_image_path}\")\n",
        "    classify_image_file(model, test_image_path)\n",
        "\n",
        "# Cell 7: Load saved model (for future use)\n",
        "# Add this cell if you want to load the saved model later\n",
        "\n",
        "def load_saved_model(model_path='/content/drive/MyDrive/emotion_recognition_model.h5'):\n",
        "    \"\"\"Load the saved model\"\"\"\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        print(f\"Model loaded successfully from {model_path}\")\n",
        "        return loaded_model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "7kaWxdjoWKYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "729smrqsWKbc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}